{
  
    
        "post0": {
            "title": "Title",
            "content": "Putting It All Together . def init_params(size, std=1.0): return (torch.randn(size)*std).requires_grad_() . weights = init_params((28*28,1)) bias = init_params(1) . path = untar_data(URLs.MNIST) Path.BASE_PATH = path path.ls() (path/&#39;training&#39;).ls() zeroes = (path/&#39;training&#39;/&#39;0&#39;).ls().sorted() ones = (path/&#39;training&#39;/&#39;1&#39;).ls().sorted() twos = (path/&#39;training&#39;/&#39;2&#39;).ls().sorted() threes = (path/&#39;training&#39;/&#39;3&#39;).ls().sorted() fours = (path/&#39;training&#39;/&#39;4&#39;).ls().sorted() fives = (path/&#39;training&#39;/&#39;5&#39;).ls().sorted() sixes = (path/&#39;training&#39;/&#39;6&#39;).ls().sorted() sevens = (path/&#39;training&#39;/&#39;7&#39;).ls().sorted() eights = (path/&#39;training&#39;/&#39;8&#39;).ls().sorted() nines = (path/&#39;training&#39;/&#39;9&#39;).ls().sorted() zeroes_tensors = [tensor(Image.open(o)) for o in zeroes] ones_tensors = [tensor(Image.open(o)) for o in ones] twoes_tensors = [tensor(Image.open(o)) for o in twos] threes_tensors = [tensor(Image.open(o)) for o in threes] fours_tensors = [tensor(Image.open(o)) for o in fours] fives_tensors = [tensor(Image.open(o)) for o in fives] sixes_tensors = [tensor(Image.open(o)) for o in sixes] seven_tensors = [tensor(Image.open(o)) for o in sevens] eights_tensors = [tensor(Image.open(o)) for o in eights] nines_tensors = [tensor(Image.open(o)) for o in nines] stacked_zeroes = torch.stack(zeroes_tensors).float()/255 stacked_ones = torch.stack(ones_tensors).float()/255 stacked_twos = torch.stack(twoes_tensors).float()/255 stacked_threes = torch.stack(threes_tensors).float()/255 stacked_fours = torch.stack(fours_tensors).float()/255 stacked_fives = torch.stack(fives_tensors).float()/255 stacked_sixes = torch.stack(sixes_tensors).float()/255 stacked_sevens = torch.stack(seven_tensors).float()/255 stacked_eights = torch.stack(eights_tensors).float()/255 stacked_nines = torch.stack(nines_tensors).float()/255 train_x = torch.cat([stacked_zeroes,stacked_ones,stacked_twos,stacked_threes,stacked_fours,stacked_fives,stacked_sixes,stacked_sevens,stacked_eights,stacked_nines]).view(-1, 28*28) train_y = tensor([0]*len(zeroes) + [1]*len(ones) + [2]*len(twos) + [3]*len(threes) + [4]*len(fours) + [5]*len(fives) + [6]*len(sixes) + [7]*len(sevens) + [8]*len(eights) + [9]*len(nines)).unsqueeze(1) dset = list(zip(train_x,train_y)) dl = DataLoader(dset, batch_size=256) valid_0_tens = torch.stack([tensor(Image.open(o)) for o in (path/&#39;testing&#39;/&#39;0&#39;).ls()]) valid_0_tens = valid_0_tens.float()/255 valid_1_tens = torch.stack([tensor(Image.open(o)) for o in (path/&#39;testing&#39;/&#39;1&#39;).ls()]) valid_1_tens = valid_1_tens.float()/255 valid_2_tens = torch.stack([tensor(Image.open(o)) for o in (path/&#39;testing&#39;/&#39;2&#39;).ls()]) valid_2_tens = valid_2_tens.float()/255 valid_3_tens = torch.stack([tensor(Image.open(o)) for o in (path/&#39;testing&#39;/&#39;3&#39;).ls()]) valid_3_tens = valid_3_tens.float()/255 valid_4_tens = torch.stack([tensor(Image.open(o)) for o in (path/&#39;testing&#39;/&#39;4&#39;).ls()]) valid_4_tens = valid_4_tens.float()/255 valid_5_tens = torch.stack([tensor(Image.open(o)) for o in (path/&#39;testing&#39;/&#39;5&#39;).ls()]) valid_5_tens = valid_5_tens.float()/255 valid_6_tens = torch.stack([tensor(Image.open(o)) for o in (path/&#39;testing&#39;/&#39;6&#39;).ls()]) valid_6_tens = valid_6_tens.float()/255 valid_7_tens = torch.stack([tensor(Image.open(o)) for o in (path/&#39;testing&#39;/&#39;7&#39;).ls()]) valid_7_tens = valid_7_tens.float()/255 valid_8_tens = torch.stack([tensor(Image.open(o)) for o in (path/&#39;testing&#39;/&#39;8&#39;).ls()]) valid_8_tens = valid_8_tens.float()/255 valid_9_tens = torch.stack([tensor(Image.open(o)) for o in (path/&#39;testing&#39;/&#39;9&#39;).ls()]) valid_9_tens = valid_9_tens.float()/255 valid_x = torch.cat([valid_0_tens, valid_1_tens, valid_2_tens, valid_3_tens, valid_4_tens, valid_5_tens, valid_6_tens, valid_7_tens, valid_8_tens, valid_9_tens]).view(-1, 28*28) valid_y = tensor([0]*len(valid_0_tens) + [1]*len(valid_1_tens) + [2]*len(valid_2_tens) + [3]*len(valid_3_tens) + [4]*len(valid_4_tens) + [5]*len(valid_5_tens) + [6]*len(valid_6_tens) + [7]*len(valid_7_tens) + [8]*len(valid_8_tens) + [9]*len(valid_9_tens)).unsqueeze(1) valid_dset = list(zip(valid_x,valid_y)) valid_dl = DataLoader(valid_dset, batch_size=256) . path = untar_data(URLs.MNIST_SAMPLE) Path.BASE_PATH = path path.ls() (path/&#39;train&#39;).ls() threes = (path/&#39;train&#39;/&#39;3&#39;).ls().sorted() sevens = (path/&#39;train&#39;/&#39;7&#39;).ls().sorted() seven_tensors = [tensor(Image.open(o)) for o in sevens] three_tensors = [tensor(Image.open(o)) for o in threes] stacked_sevens = torch.stack(seven_tensors).float()/255 stacked_threes = torch.stack(three_tensors).float()/255 train_x = torch.cat([stacked_threes, stacked_sevens]).view(-1, 28*28) train_y = tensor([1]*len(threes) + [0]*len(sevens)).unsqueeze(1) dset = list(zip(train_x,train_y)) dl = DataLoader(dset, batch_size=256) valid_3_tens = torch.stack([tensor(Image.open(o)) for o in (path/&#39;valid&#39;/&#39;3&#39;).ls()]) valid_3_tens = valid_3_tens.float()/255 valid_7_tens = torch.stack([tensor(Image.open(o)) for o in (path/&#39;valid&#39;/&#39;7&#39;).ls()]) valid_7_tens = valid_7_tens.float()/255 valid_3_tens.shape,valid_7_tens.shape valid_x = torch.cat([valid_3_tens, valid_7_tens]).view(-1, 28*28) valid_y = tensor([1]*len(valid_3_tens) + [0]*len(valid_7_tens)).unsqueeze(1) valid_dset = list(zip(valid_x,valid_y)) valid_dl = DataLoader(valid_dset, batch_size=256) . batch = train_x[:4] . def linear1(xb): return xb@weights + bias . preds = linear1(batch) . def sigmoid(x): return 1/(1+torch.exp(-x)) . def mnist_loss(predictions, targets): predictions = predictions.sigmoid() return torch.where(targets==1, 1-predictions, predictions).mean() . loss = mnist_loss(preds, train_y[:4]) . loss.backward() weights.grad.shape,weights.grad.mean(),bias.grad . (torch.Size([784, 1]), tensor(4.4802e-05), tensor([0.0003])) . def calc_grad(xb, yb, model): preds = model(xb) loss = mnist_loss(preds, yb) loss.backward() . calc_grad(batch, train_y[:4], linear1) weights.grad.mean(),bias.grad . (tensor(8.9603e-05), tensor([0.0005])) . calc_grad(batch, train_y[:4], linear1) weights.grad.mean(),bias.grad . (tensor(0.0001), tensor([0.0008])) . weights.grad.zero_() bias.grad.zero_(); . def train_epoch(model, lr, params): for xb,yb in dl: calc_grad(xb, yb, model) for p in params: p.data -= p.grad*lr p.grad.zero_() . (preds&gt;0.0).float() == train_y[:4] . tensor([[True], [True], [True], [True]]) . def batch_accuracy(xb, yb): preds = xb.sigmoid() correct = (preds&gt;0.5) == yb return correct.float().mean() . batch_accuracy(linear1(batch), train_y[:4]) . tensor(1.) . def validate_epoch(model): accs = [batch_accuracy(model(xb), yb) for xb,yb in valid_dl] return round(torch.stack(accs).mean().item(), 4) . validate_epoch(linear1) . 0.0942 . lr = 1. params = weights,bias train_epoch(linear1, lr, params) validate_epoch(linear1) . 0.098 . for i in range(20): train_epoch(linear1, lr, params) print(validate_epoch(linear1), end=&#39; &#39;) . 0.098 0.098 0.0991 0.1001 0.102 0.1033 0.1048 0.1057 0.1066 0.1074 0.1086 0.1095 0.1099 0.1106 0.1119 0.1124 0.1133 0.1134 0.114 0.1147 . dls = DataLoaders(dl, valid_dl) . Creating an Optimizer . linear_model = nn.Linear(28*28,1) . w,b = linear_model.parameters() . class BasicOptim: def __init__(self,params,lr): self.params,self.lr = list(params),lr def step(self, *args, **kwargs): for p in self.params: p.data -= p.grad.data * self.lr def zero_grad(self, *args, **kwargs): for p in self.params: p.grad = None . opt = BasicOptim(linear_model.parameters(), lr) . def train_epoch(model): for xb,yb in dl: calc_grad(xb, yb, model) opt.step() opt.zero_grad() . validate_epoch(linear_model) . 0.0769 . def train_model(model, epochs): for i in range(epochs): train_epoch(model) print(validate_epoch(model), end=&#39; &#39;) . train_model(linear_model, 20) . 0.098 0.098 0.098 0.098 0.0982 0.0984 0.0988 0.0998 0.1006 0.1021 0.1038 0.1052 0.1063 0.1067 0.107 0.1072 0.1082 0.1088 0.1089 0.1087 . linear_model = nn.Linear(28*28,1) opt = SGD(linear_model.parameters(), lr) train_model(linear_model, 20) . 0.098 0.098 0.098 0.098 0.0982 0.0984 0.0987 0.0994 0.0998 0.101 0.1025 0.1041 0.1056 0.1063 0.1064 0.1066 0.1075 0.108 0.1079 0.1085 . learn = Learner(dls, nn.Linear(28*28,1), opt_func=SGD, loss_func=mnist_loss, metrics=batch_accuracy) . learn.fit(10, lr=lr) . . 70.00% [7/10 00:12&lt;00:05] epoch train_loss valid_loss batch_accuracy time . 0 | 0.000645 | 0.104988 | 0.104700 | 00:01 | . 1 | 0.000482 | 0.086720 | 0.124500 | 00:01 | . 2 | 0.000608 | 0.078033 | 0.133400 | 00:01 | . 3 | 0.000694 | 0.074158 | 0.136800 | 00:01 | . 4 | 0.000642 | 0.073499 | 0.138000 | 00:01 | . 5 | 0.000617 | 0.051463 | 0.160400 | 00:01 | . 6 | 0.000546 | 0.070548 | 0.141000 | 00:01 | . . 30.21% [71/235 00:00&lt;00:01 0.0107] &lt;/div&gt; &lt;/div&gt; KeyboardInterrupt Traceback (most recent call last) &lt;ipython-input-74-1743e6f42408&gt; in &lt;module&gt;() -&gt; 1 learn.fit(10, lr=lr) /usr/local/lib/python3.7/dist-packages/fastai/learner.py in fit(self, n_epoch, lr, wd, cbs, reset_opt) 209 self.opt.set_hypers(lr=self.lr if lr is None else lr) 210 self.n_epoch = n_epoch --&gt; 211 self._with_events(self._do_fit, &#39;fit&#39;, CancelFitException, self._end_cleanup) 212 213 def _end_cleanup(self): self.dl,self.xb,self.yb,self.pred,self.loss = None,(None,),(None,),None,None /usr/local/lib/python3.7/dist-packages/fastai/learner.py in _with_events(self, f, event_type, ex, final) 158 159 def _with_events(self, f, event_type, ex, final=noop): --&gt; 160 try: self(f&#39;before_{event_type}&#39;); f() 161 except ex: self(f&#39;after_cancel_{event_type}&#39;) 162 self(f&#39;after_{event_type}&#39;); final() /usr/local/lib/python3.7/dist-packages/fastai/learner.py in _do_fit(self) 200 for epoch in range(self.n_epoch): 201 self.epoch=epoch --&gt; 202 self._with_events(self._do_epoch, &#39;epoch&#39;, CancelEpochException) 203 204 def fit(self, n_epoch, lr=None, wd=None, cbs=None, reset_opt=False): /usr/local/lib/python3.7/dist-packages/fastai/learner.py in _with_events(self, f, event_type, ex, final) 158 159 def _with_events(self, f, event_type, ex, final=noop): --&gt; 160 try: self(f&#39;before_{event_type}&#39;); f() 161 except ex: self(f&#39;after_cancel_{event_type}&#39;) 162 self(f&#39;after_{event_type}&#39;); final() /usr/local/lib/python3.7/dist-packages/fastai/learner.py in _do_epoch(self) 194 195 def _do_epoch(self): --&gt; 196 self._do_epoch_train() 197 self._do_epoch_validate() 198 /usr/local/lib/python3.7/dist-packages/fastai/learner.py in _do_epoch_train(self) 186 def _do_epoch_train(self): 187 self.dl = self.dls.train --&gt; 188 self._with_events(self.all_batches, &#39;train&#39;, CancelTrainException) 189 190 def _do_epoch_validate(self, ds_idx=1, dl=None): /usr/local/lib/python3.7/dist-packages/fastai/learner.py in _with_events(self, f, event_type, ex, final) 158 159 def _with_events(self, f, event_type, ex, final=noop): --&gt; 160 try: self(f&#39;before_{event_type}&#39;); f() 161 except ex: self(f&#39;after_cancel_{event_type}&#39;) 162 self(f&#39;after_{event_type}&#39;); final() /usr/local/lib/python3.7/dist-packages/fastai/learner.py in all_batches(self) 164 def all_batches(self): 165 self.n_iter = len(self.dl) --&gt; 166 for o in enumerate(self.dl): self.one_batch(*o) 167 168 def _do_one_batch(self): /usr/local/lib/python3.7/dist-packages/fastai/learner.py in one_batch(self, i, b) 182 self.iter = i 183 self._split(b) --&gt; 184 self._with_events(self._do_one_batch, &#39;batch&#39;, CancelBatchException) 185 186 def _do_epoch_train(self): /usr/local/lib/python3.7/dist-packages/fastai/learner.py in _with_events(self, f, event_type, ex, final) 158 159 def _with_events(self, f, event_type, ex, final=noop): --&gt; 160 try: self(f&#39;before_{event_type}&#39;); f() 161 except ex: self(f&#39;after_cancel_{event_type}&#39;) 162 self(f&#39;after_{event_type}&#39;); final() /usr/local/lib/python3.7/dist-packages/fastai/learner.py in _do_one_batch(self) 167 168 def _do_one_batch(self): --&gt; 169 self.pred = self.model(*self.xb) 170 self(&#39;after_pred&#39;) 171 if len(self.yb): /usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py in _call_impl(self, *input, **kwargs) 725 result = self._slow_forward(*input, **kwargs) 726 else: --&gt; 727 result = self.forward(*input, **kwargs) 728 for hook in itertools.chain( 729 _global_forward_hooks.values(), /usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py in forward(self, input) 115 def forward(self, input): 116 for module in self: --&gt; 117 input = module(input) 118 return input 119 /usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py in _call_impl(self, *input, **kwargs) 725 result = self._slow_forward(*input, **kwargs) 726 else: --&gt; 727 result = self.forward(*input, **kwargs) 728 for hook in itertools.chain( 729 _global_forward_hooks.values(), /usr/local/lib/python3.7/dist-packages/torch/nn/modules/linear.py in forward(self, input) 91 92 def forward(self, input: Tensor) -&gt; Tensor: &gt; 93 return F.linear(input, self.weight, self.bias) 94 95 def extra_repr(self) -&gt; str: /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py in linear(input, weight, bias) 1688 if input.dim() == 2 and bias is not None: 1689 # fused op is marginally faster -&gt; 1690 ret = torch.addmm(bias, input, weight.t()) 1691 else: 1692 output = input.matmul(weight.t()) KeyboardInterrupt: . &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; Adding a Nonlinearity . features = 90 nrOfLayers = 0 layers = [] layers.append(nn.Linear(28*28,features)) for i in range(nrOfLayers): layers.append(nn.ReLU()) layers.append(nn.Linear(features,features)) layers.append(nn.ReLU()) layers.append(nn.Linear(features,1)) print(&#39;Nr of layers&#39;, len(layers)) layers . Nr of layers 3 . [Linear(in_features=784, out_features=90, bias=True), ReLU(), Linear(in_features=90, out_features=1, bias=True)] . simple_net = nn.Sequential(*layers) . learn = Learner(dls, simple_net, opt_func=SGD, loss_func=mnist_loss, metrics=batch_accuracy) . learn.fit(50, 1.0) . epoch train_loss valid_loss batch_accuracy time . 0 | 0.002604 | 0.111212 | 0.098000 | 00:01 | . 1 | 0.001329 | 0.097870 | 0.107700 | 00:01 | . 2 | 0.000930 | 0.092041 | 0.117100 | 00:01 | . 3 | 0.000873 | 0.087795 | 0.121700 | 00:01 | . 4 | 0.000879 | 0.083624 | 0.127600 | 00:01 | . 5 | 0.000905 | 0.079636 | 0.132200 | 00:01 | . 6 | 0.000929 | 0.076391 | 0.135000 | 00:01 | . 7 | 0.000950 | 0.073506 | 0.138300 | 00:01 | . 8 | 0.000969 | 0.070597 | 0.142000 | 00:01 | . 9 | 0.000986 | 0.068260 | 0.143900 | 00:01 | . 10 | 0.000994 | 0.065818 | 0.146200 | 00:01 | . 11 | 0.001001 | 0.063694 | 0.148500 | 00:01 | . 12 | 0.001001 | 0.061537 | 0.151300 | 00:01 | . 13 | 0.001010 | 0.060394 | 0.152500 | 00:01 | . 14 | 0.001007 | 0.057467 | 0.156200 | 00:01 | . 15 | 0.001005 | 0.056069 | 0.156900 | 00:01 | . 16 | 0.000996 | 0.053122 | 0.159900 | 00:01 | . 17 | 0.000986 | 0.051553 | 0.161300 | 00:01 | . 18 | 0.000975 | 0.048800 | 0.164000 | 00:01 | . 19 | 0.000966 | 0.047040 | 0.165600 | 00:01 | . 20 | 0.000969 | 0.043970 | 0.168400 | 00:01 | . 21 | 0.000975 | 0.042065 | 0.170500 | 00:01 | . 22 | 0.000990 | 0.039492 | 0.173400 | 00:01 | . 23 | 0.001000 | 0.037980 | 0.174700 | 00:01 | . 24 | 0.001019 | 0.035686 | 0.177400 | 00:01 | . 25 | 0.001035 | 0.034079 | 0.179400 | 00:01 | . 26 | 0.001046 | 0.032285 | 0.180800 | 00:01 | . 27 | 0.001055 | 0.031533 | 0.181700 | 00:01 | . 28 | 0.001062 | 0.029820 | 0.183700 | 00:01 | . 29 | 0.001072 | 0.028288 | 0.185300 | 00:01 | . 30 | 0.001073 | 0.027617 | 0.185900 | 00:01 | . 31 | 0.001085 | 0.026700 | 0.186500 | 00:01 | . 32 | 0.001088 | 0.025756 | 0.187500 | 00:01 | . 33 | 0.001095 | 0.025093 | 0.188400 | 00:01 | . 34 | 0.001098 | 0.024270 | 0.189000 | 00:01 | . 35 | 0.001102 | 0.023724 | 0.189600 | 00:01 | . 36 | 0.001105 | 0.023301 | 0.189800 | 00:01 | . 37 | 0.001107 | 0.022698 | 0.190600 | 00:01 | . 38 | 0.001108 | 0.022417 | 0.190800 | 00:01 | . 39 | 0.001104 | 0.021719 | 0.191500 | 00:01 | . 40 | 0.001099 | 0.021492 | 0.191900 | 00:01 | . 41 | 0.001093 | 0.020864 | 0.192200 | 00:01 | . 42 | 0.001094 | 0.020424 | 0.192400 | 00:01 | . 43 | 0.001087 | 0.019747 | 0.192900 | 00:01 | . 44 | 0.001084 | 0.019268 | 0.193500 | 00:01 | . 45 | 0.001072 | 0.018620 | 0.194400 | 00:01 | . 46 | 0.001062 | 0.018115 | 0.194900 | 00:01 | . 47 | 0.001046 | 0.017500 | 0.195700 | 00:01 | . 48 | 0.001021 | 0.016856 | 0.196400 | 00:01 | . 49 | 0.000998 | 0.016313 | 0.196700 | 00:01 | . plt.plot(L(learn.recorder.values).itemgot(2)); . learn.recorder.values[-1][2] . 0.19670000672340393 . &lt;/div&gt; .",
            "url": "https://tobbe3108.github.io/Fast.ai.Blog/2021/03/02/Under-the-Hood.html",
            "relUrl": "/2021/03/02/Under-the-Hood.html",
            "date": " • Mar 2, 2021"
        }
        
    
  
    
        ,"post1": {
            "title": "Playstation Classifier",
            "content": "Setup . import zipfile with zipfile.ZipFile(&#39;images/playstation.zip&#39;, &#39;r&#39;) as zip_ref: zip_ref.extractall() . key = os.environ.get(&#39;AZURE_SEARCH_KEY&#39;, &#39;0a449f766989411ea479770904e9cd75&#39;) . bear_types = &#39;1&#39;,&#39;2&#39;,&#39;3&#39;,&#39;4&#39;,&#39;5&#39; path = Path(&#39;images/playstation&#39;) . File download . if not path.exists(): path.mkdir() for o in bear_types: dest = (path/o) dest.mkdir(exist_ok=True) results = search_images_bing(key, f&#39;{o} bear&#39;) download_images(dest, urls=results.attrgot(&#39;contentUrl&#39;)) . File tests . fns = get_image_files(path) fns . (#736) [Path(&#39;images/playstation/3/00000047.jpg&#39;),Path(&#39;images/playstation/3/00000055.jpg&#39;),Path(&#39;images/playstation/3/00000012.jpeg&#39;),Path(&#39;images/playstation/3/00000107.jpg&#39;),Path(&#39;images/playstation/3/00000036.jpg&#39;),Path(&#39;images/playstation/3/00000000.png_client=cbc79c14efcebee57402_signature=3c726b1d9ab6205b82f733bc6f6f4a6b88a874de.png&#39;),Path(&#39;images/playstation/3/00000097.jpg&#39;),Path(&#39;images/playstation/3/00000148.jpg&#39;),Path(&#39;images/playstation/3/00000145.jpeg&#39;),Path(&#39;images/playstation/3/00000110.jpg&#39;)...] . failed = verify_images(fns) failed . (#0) [] . failed.map(Path.unlink); . bears = DataBlock( blocks=(ImageBlock, CategoryBlock), get_items=get_image_files, splitter=RandomSplitter(valid_pct=0.2, seed=42), get_y=parent_label, item_tfms=Resize(128)) . dls = bears.dataloaders(path) . dls.valid.show_batch(max_n=4, nrows=1) . Model training . bears = bears.new( item_tfms=RandomResizedCrop(224, min_scale=0.5), batch_tfms=aug_transforms()) dls = bears.dataloaders(path) . learn = cnn_learner(dls, resnet18, metrics=error_rate) learn.fine_tune(4) . Downloading: &#34;https://download.pytorch.org/models/resnet18-5c106cde.pth&#34; to /root/.cache/torch/hub/checkpoints/resnet18-5c106cde.pth . . epoch train_loss valid_loss error_rate time . 0 | 2.200467 | 1.151368 | 0.394558 | 00:11 | . /opt/conda/envs/fastai/lib/python3.8/site-packages/PIL/Image.py:951: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images warnings.warn( /opt/conda/envs/fastai/lib/python3.8/site-packages/PIL/Image.py:951: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images warnings.warn( /opt/conda/envs/fastai/lib/python3.8/site-packages/PIL/Image.py:951: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images warnings.warn( /opt/conda/envs/fastai/lib/python3.8/site-packages/PIL/Image.py:951: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images warnings.warn( /opt/conda/envs/fastai/lib/python3.8/site-packages/PIL/Image.py:951: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images warnings.warn( /opt/conda/envs/fastai/lib/python3.8/site-packages/PIL/Image.py:951: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images warnings.warn( . epoch train_loss valid_loss error_rate time . 0 | 0.995675 | 0.812293 | 0.299320 | 00:13 | . 1 | 0.832542 | 0.495169 | 0.176871 | 00:13 | . 2 | 0.679947 | 0.392348 | 0.142857 | 00:14 | . 3 | 0.565052 | 0.389338 | 0.149660 | 00:13 | . /opt/conda/envs/fastai/lib/python3.8/site-packages/PIL/Image.py:951: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images warnings.warn( /opt/conda/envs/fastai/lib/python3.8/site-packages/PIL/Image.py:951: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images warnings.warn( /opt/conda/envs/fastai/lib/python3.8/site-packages/PIL/Image.py:951: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images warnings.warn( /opt/conda/envs/fastai/lib/python3.8/site-packages/PIL/Image.py:951: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images warnings.warn( /opt/conda/envs/fastai/lib/python3.8/site-packages/PIL/Image.py:951: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images warnings.warn( /opt/conda/envs/fastai/lib/python3.8/site-packages/PIL/Image.py:951: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images warnings.warn( /opt/conda/envs/fastai/lib/python3.8/site-packages/PIL/Image.py:951: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images warnings.warn( /opt/conda/envs/fastai/lib/python3.8/site-packages/PIL/Image.py:951: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images warnings.warn( /opt/conda/envs/fastai/lib/python3.8/site-packages/PIL/Image.py:951: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images warnings.warn( /opt/conda/envs/fastai/lib/python3.8/site-packages/PIL/Image.py:951: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images warnings.warn( /opt/conda/envs/fastai/lib/python3.8/site-packages/PIL/Image.py:951: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images warnings.warn( /opt/conda/envs/fastai/lib/python3.8/site-packages/PIL/Image.py:951: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images warnings.warn( /opt/conda/envs/fastai/lib/python3.8/site-packages/PIL/Image.py:951: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images warnings.warn( /opt/conda/envs/fastai/lib/python3.8/site-packages/PIL/Image.py:951: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images warnings.warn( /opt/conda/envs/fastai/lib/python3.8/site-packages/PIL/Image.py:951: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images warnings.warn( /opt/conda/envs/fastai/lib/python3.8/site-packages/PIL/Image.py:951: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images warnings.warn( /opt/conda/envs/fastai/lib/python3.8/site-packages/PIL/Image.py:951: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images warnings.warn( /opt/conda/envs/fastai/lib/python3.8/site-packages/PIL/Image.py:951: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images warnings.warn( /opt/conda/envs/fastai/lib/python3.8/site-packages/PIL/Image.py:951: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images warnings.warn( /opt/conda/envs/fastai/lib/python3.8/site-packages/PIL/Image.py:951: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images warnings.warn( . interp = ClassificationInterpretation.from_learner(learn) interp.plot_confusion_matrix() . /opt/conda/envs/fastai/lib/python3.8/site-packages/PIL/Image.py:951: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images warnings.warn( . interp.plot_top_losses(5, nrows=1) . Data cleaning . cleaner = ImageClassifierCleaner(learn) cleaner . Exporting . learn.export() . NameError Traceback (most recent call last) &lt;ipython-input-8-fa5b61306ef3&gt; in &lt;module&gt; -&gt; 1 learn.export() NameError: name &#39;learn&#39; is not defined . path = Path() path.ls(file_exts=&#39;.pkl&#39;) . learn_inf = load_learner(path/&#39;export.pkl&#39;) . learn_inf.predict(&#39;images/grizzly.jpg&#39;) . learn_inf.dls.vocab . App . learn_inf = load_learner(&#39;export.pkl&#39;) . img = PILImage.create(&#39;ps5.jpg&#39;) . out_pl = widgets.Output() out_pl.clear_output() with out_pl: display(img.to_thumb(128,128)) out_pl . pred,pred_idx,probs = learn_inf.predict(img) . lbl_pred = widgets.Label() lbl_pred.value = f&#39;Prediction: Playstation {pred}; Probability: {probs[pred_idx]:.04f}&#39; lbl_pred . btn_run = widgets.Button(description=&#39;Classify&#39;) btn_run . def on_click_classify(change): img = PILImage.create(btn_upload.data[-1]) out_pl.clear_output() with out_pl: display(img.to_thumb(128,128)) pred,pred_idx,probs = learn_inf.predict(img) lbl_pred.value = f&#39;Prediction: Playstation {pred}; Probability: {probs[pred_idx]:.04f}&#39; btn_run.on_click(on_click_classify) . VBox([widgets.Label(&#39;Select your bear!&#39;), btn_upload, btn_run, out_pl, lbl_pred]) .",
            "url": "https://tobbe3108.github.io/Fast.ai.Blog/2021/02/16/Playstation-Classifier.html",
            "relUrl": "/2021/02/16/Playstation-Classifier.html",
            "date": " • Feb 16, 2021"
        }
        
    
  
    
        ,"post2": {
            "title": "Maleri Classifier",
            "content": "Setup . !pip install -Uqq fastbook import fastbook fastbook.setup_book() . |████████████████████████████████| 727kB 12.8MB/s |████████████████████████████████| 194kB 23.8MB/s |████████████████████████████████| 51kB 4.5MB/s |████████████████████████████████| 1.2MB 35.7MB/s |████████████████████████████████| 61kB 5.9MB/s Mounted at /content/gdrive . from fastbook import * from fastai.vision.widgets import * . bear_types = &#39;Abildgaard, Nicolai&#39;,&#39;Dahl, J.C&#39;,&#39;Eckersberg, C.W&#39;,&#39;Hammershøi, Vilhelm&#39;,&#39;Hansen, Constantin&#39;,&#39;Jensen, C.A&#39;,&#39;Juel, Jens&#39;,&#39;Krøyer, P.S&#39;,&#39;Kyhn, Vilhelm&#39;,&#39;Købke, Christen&#39;,&#39;Lorentzen, C.A&#39;,&#39;Marstrand, Wilhelm&#39;,&#39;Pauelsen, Erik&#39;,&#39;Philipsen, Theodor&#39;,&#39;Skovgaard, P.C&#39; path = Path(&#39;Images/paintings&#39;) . File tests . fns = get_image_files(path) fns . (#604) [Path(&#39;Images/paintings/Kroyer, P.S/019.jpg&#39;),Path(&#39;Images/paintings/Kroyer, P.S/013.jpg&#39;),Path(&#39;Images/paintings/Kroyer, P.S/016.jpg&#39;),Path(&#39;Images/paintings/Kroyer, P.S/017.jpg&#39;),Path(&#39;Images/paintings/Kroyer, P.S/006.jpg&#39;),Path(&#39;Images/paintings/Kroyer, P.S/001.jpg&#39;),Path(&#39;Images/paintings/Kroyer, P.S/008.jpg&#39;),Path(&#39;Images/paintings/Kroyer, P.S/007.jpg&#39;),Path(&#39;Images/paintings/Kroyer, P.S/010.jpg&#39;),Path(&#39;Images/paintings/Kroyer, P.S/011.jpg&#39;)...] . failed = verify_images(fns) failed . (#0) [] . failed.map(Path.unlink); . bears = DataBlock( blocks=(ImageBlock, CategoryBlock), get_items=get_image_files, splitter=RandomSplitter(valid_pct=0.2, seed=42), get_y=parent_label, item_tfms=Resize(128)) . dls = bears.dataloaders(path) . dls.valid.show_batch(max_n=4, nrows=1) . Model training . bears = bears.new( item_tfms=RandomResizedCrop(224, min_scale=0.5), batch_tfms=aug_transforms()) dls = bears.dataloaders(path) . learn = cnn_learner(dls, resnet18, metrics=error_rate) learn.fine_tune(4) . Downloading: &#34;https://download.pytorch.org/models/resnet18-5c106cde.pth&#34; to /root/.cache/torch/hub/checkpoints/resnet18-5c106cde.pth . . epoch train_loss valid_loss error_rate time . 0 | 3.917598 | 2.874836 | 0.791667 | 01:49 | . epoch train_loss valid_loss error_rate time . 0 | 2.970143 | 2.576576 | 0.716667 | 02:16 | . 1 | 2.644958 | 2.366002 | 0.683333 | 02:14 | . 2 | 2.341411 | 2.299324 | 0.666667 | 02:14 | . 3 | 2.163972 | 2.296838 | 0.658333 | 02:21 | . interp = ClassificationInterpretation.from_learner(learn) interp.plot_confusion_matrix() . interp.plot_top_losses(5, nrows=1) . Data cleaning . cleaner = ImageClassifierCleaner(learn) cleaner . # for idx,cat in cleaner.change(): shutil.move(str(cleaner.fns[idx]), path/cat) . Exporting . learn.export() . path = Path() path.ls(file_exts=&#39;.pkl&#39;) . (#1) [Path(&#39;export.pkl&#39;)] . learn_inf = load_learner(path/&#39;export.pkl&#39;) . learn_inf.predict(&#39;Images/painting.jpg&#39;) . (&#39;Marstrand, Wilhelm&#39;, tensor(11), tensor([0.2217, 0.0525, 0.0057, 0.0223, 0.0413, 0.0789, 0.0022, 0.0418, 0.0257, 0.0107, 0.1611, 0.2983, 0.0207, 0.0045, 0.0125])) . learn_inf.dls.vocab . [&#39;Abildgaard, Nicolai&#39;, &#39;Dahl, J.C&#39;, &#39;Eckersberg, C.W&#39;, &#39;Hammershoi, Vilhelm&#39;, &#39;Hansen, Constantin&#39;, &#39;Jensen, C.A&#39;, &#39;Juel, Jens&#39;, &#39;Kobke, Christen&#39;, &#39;Kroyer, P.S&#39;, &#39;Kyhn, Vilhelm&#39;, &#39;Lorentzen, C.A&#39;, &#39;Marstrand, Wilhelm&#39;, &#39;Pauelsen, Erik&#39;, &#39;Philipsen, Theodor&#39;, &#39;Skovgaard, P.C&#39;] . App . learn_inf = load_learner(&#39;export.pkl&#39;) . img = PILImage.create(&#39;Images/painting.jpg&#39;) . out_pl = widgets.Output() out_pl.clear_output() with out_pl: display(img.to_thumb(128,128)) out_pl . pred,pred_idx,probs = learn_inf.predict(img) . lbl_pred = widgets.Label() lbl_pred.value = f&#39;Prediction: {pred}; Probability: {probs[pred_idx]:.04f}&#39; lbl_pred . btn_run = widgets.Button(description=&#39;Classify&#39;) btn_run . def on_click_classify(change): img = PILImage.create(btn_upload.data[-1]) out_pl.clear_output() with out_pl: display(img.to_thumb(128,128)) pred,pred_idx,probs = learn_inf.predict(img) lbl_pred.value = f&#39;Prediction: {pred}; Probability: {probs[pred_idx]:.04f}&#39; btn_run.on_click(on_click_classify) . btn_upload = widgets.FileUpload() . VBox([widgets.Label(&#39;Select your painting!&#39;), btn_upload, btn_run, out_pl, lbl_pred]) .",
            "url": "https://tobbe3108.github.io/Fast.ai.Blog/2021/02/16/Maleri-Classifier.html",
            "relUrl": "/2021/02/16/Maleri-Classifier.html",
            "date": " • Feb 16, 2021"
        }
        
    
  
    
        ,"post3": {
            "title": "Maleri Classifier v2",
            "content": "This time with 134 more layers . Setup . !pip install -Uqq fastbook import fastbook fastbook.setup_book() . from fastbook import * from fastai.vision.widgets import * . types = &#39;Abildgaard, Nicolai&#39;,&#39;Dahl, J.C&#39;,&#39;Eckersberg, C.W&#39;,&#39;Hammershøi, Vilhelm&#39;,&#39;Hansen, Constantin&#39;,&#39;Jensen, C.A&#39;,&#39;Juel, Jens&#39;,&#39;Krøyer, P.S&#39;,&#39;Kyhn, Vilhelm&#39;,&#39;Købke, Christen&#39;,&#39;Lorentzen, C.A&#39;,&#39;Marstrand, Wilhelm&#39;,&#39;Pauelsen, Erik&#39;,&#39;Philipsen, Theodor&#39;,&#39;Skovgaard, P.C&#39; path = Path(&#39;gdrive/MyDrive/AI Machine Learning/images/Maleri Classifier&#39;) . File tests . fns = get_image_files(path) fns . data = DataBlock( blocks=(ImageBlock, CategoryBlock), get_items=get_image_files, splitter=RandomSplitter(valid_pct=0.2, seed=42), get_y=parent_label, item_tfms=Resize(128)) . dls = data.dataloaders(path) . Model training . data = data.new( item_tfms=RandomResizedCrop(224, min_scale=0.5), batch_tfms=aug_transforms()) dls = data.dataloaders(path) . learn = cnn_learner(dls, resnet152, metrics=error_rate) learn.fine_tune(10) . interp = ClassificationInterpretation.from_learner(learn) interp.plot_confusion_matrix() . Exporting . learn.export() . App . learn_inf = load_learner(&#39;gdrive/MyDrive/AI Machine Learning/models/MaleriExport_v2.pkl&#39;) . img = PILImage.create(&#39;gdrive/MyDrive/AI Machine Learning/images/Unknown Maleri.jpg&#39;) . out_pl = widgets.Output() out_pl.clear_output() with out_pl: display(img.to_thumb(128,128)) out_pl . pred,pred_idx,probs = learn_inf.predict(img) . lbl_pred = widgets.Label() lbl_pred.value = f&#39;Prediction: {pred}; Probability: {probs[pred_idx]:.04f}&#39; lbl_pred . btn_run = widgets.Button(description=&#39;Classify&#39;) btn_run . def on_click_classify(change): img = PILImage.create(btn_upload.data[-1]) out_pl.clear_output() with out_pl: display(img.to_thumb(128,128)) pred,pred_idx,probs = learn_inf.predict(img) lbl_pred.value = f&#39;Prediction: {pred}; Probability: {probs[pred_idx]:.04f}&#39; btn_run.on_click(on_click_classify) . btn_upload = widgets.FileUpload() . VBox([widgets.Label(&#39;Select your painting!&#39;), btn_upload, btn_run, out_pl, lbl_pred]) .",
            "url": "https://tobbe3108.github.io/Fast.ai.Blog/2021/02/16/Maleri-Classifier-v2.html",
            "relUrl": "/2021/02/16/Maleri-Classifier-v2.html",
            "date": " • Feb 16, 2021"
        }
        
    
  
    
        ,"post4": {
            "title": "Hotdog Classifier",
            "content": "Setup . import zipfile with zipfile.ZipFile(&#39;images/playstation.zip&#39;, &#39;r&#39;) as zip_ref: zip_ref.extractall() . key = os.environ.get(&#39;AZURE_SEARCH_KEY&#39;, &#39;0a449f766989411ea479770904e9cd75&#39;) . bear_types = &#39;hotdog&#39;,&#39;random&#39; path = Path(&#39;hotdogs&#39;) . File download . if not path.exists(): path.mkdir() for o in bear_types: dest = (path/o) dest.mkdir(exist_ok=True) results = search_images_bing(key, f&#39;{o}&#39;) download_images(dest, urls=results.attrgot(&#39;contentUrl&#39;)) . File tests . fns = get_image_files(path) fns . (#282) [Path(&#39;hotdogs/hotdog/00000034.jpg&#39;),Path(&#39;hotdogs/hotdog/00000015.jpg&#39;),Path(&#39;hotdogs/hotdog/00000002.jpg&#39;),Path(&#39;hotdogs/hotdog/00000095.jpg&#39;),Path(&#39;hotdogs/hotdog/00000096.jpg&#39;),Path(&#39;hotdogs/hotdog/00000019.jpg&#39;),Path(&#39;hotdogs/hotdog/00000044.jpg&#39;),Path(&#39;hotdogs/hotdog/00000023.jpg&#39;),Path(&#39;hotdogs/hotdog/00000033.png&#39;),Path(&#39;hotdogs/hotdog/00000108.jpg&#39;)...] . failed = verify_images(fns) failed . (#2) [Path(&#39;hotdogs/random/00000134.gif&#39;),Path(&#39;hotdogs/random/00000114.svg&#39;)] . failed.map(Path.unlink); . bears = DataBlock( blocks=(ImageBlock, CategoryBlock), get_items=get_image_files, splitter=RandomSplitter(valid_pct=0.2, seed=42), get_y=parent_label, item_tfms=Resize(128)) . dls = bears.dataloaders(path) . dls.valid.show_batch(max_n=4, nrows=1) . /usr/local/lib/python3.6/dist-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images &#34;Palette images with Transparency expressed in bytes should be &#34; . Model training . bears = bears.new( item_tfms=RandomResizedCrop(224, min_scale=0.5), batch_tfms=aug_transforms()) dls = bears.dataloaders(path) . learn = cnn_learner(dls, resnet18, metrics=error_rate) learn.fine_tune(4) . Downloading: &#34;https://download.pytorch.org/models/resnet18-5c106cde.pth&#34; to /root/.cache/torch/hub/checkpoints/resnet18-5c106cde.pth . . epoch train_loss valid_loss error_rate time . 0 | 0.939288 | 0.800330 | 0.339286 | 00:47 | . /usr/local/lib/python3.6/dist-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images &#34;Palette images with Transparency expressed in bytes should be &#34; /usr/local/lib/python3.6/dist-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images &#34;Palette images with Transparency expressed in bytes should be &#34; . epoch train_loss valid_loss error_rate time . 0 | 0.258995 | 0.127631 | 0.035714 | 01:03 | . 1 | 0.181107 | 0.013016 | 0.000000 | 01:03 | . 2 | 0.123359 | 0.002594 | 0.000000 | 01:03 | . 3 | 0.106967 | 0.001533 | 0.000000 | 01:03 | . /usr/local/lib/python3.6/dist-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images &#34;Palette images with Transparency expressed in bytes should be &#34; /usr/local/lib/python3.6/dist-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images &#34;Palette images with Transparency expressed in bytes should be &#34; /usr/local/lib/python3.6/dist-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images &#34;Palette images with Transparency expressed in bytes should be &#34; /usr/local/lib/python3.6/dist-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images &#34;Palette images with Transparency expressed in bytes should be &#34; /usr/local/lib/python3.6/dist-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images &#34;Palette images with Transparency expressed in bytes should be &#34; /usr/local/lib/python3.6/dist-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images &#34;Palette images with Transparency expressed in bytes should be &#34; /usr/local/lib/python3.6/dist-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images &#34;Palette images with Transparency expressed in bytes should be &#34; /usr/local/lib/python3.6/dist-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images &#34;Palette images with Transparency expressed in bytes should be &#34; /usr/local/lib/python3.6/dist-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images &#34;Palette images with Transparency expressed in bytes should be &#34; . interp = ClassificationInterpretation.from_learner(learn) interp.plot_confusion_matrix() . /usr/local/lib/python3.6/dist-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images &#34;Palette images with Transparency expressed in bytes should be &#34; . interp.plot_top_losses(5, nrows=1) . Data cleaning . cleaner = ImageClassifierCleaner(learn) cleaner . Exporting . learn.export() . path = Path() path.ls(file_exts=&#39;.pkl&#39;) . (#1) [Path(&#39;export.pkl&#39;)] . learn_inf = load_learner(path/&#39;export.pkl&#39;) . learn_inf.dls.vocab . App . learn_inf = load_learner(&#39;HotdogExport.pkl&#39;) . img = PILImage.create(&#39;hotdog.jpg&#39;) . out_pl = widgets.Output() out_pl.clear_output() with out_pl: display(img.to_thumb(128,128)) out_pl . pred,pred_idx,probs = learn_inf.predict(img) . lbl_pred = widgets.Label() lbl_pred.value = f&#39;Prediction: {pred}; Probability: {probs[pred_idx]:.04f}&#39; lbl_pred . btn_run = widgets.Button(description=&#39;Classify&#39;) btn_run . def on_click_classify(change): img = PILImage.create(btn_upload.data[-1]) out_pl.clear_output() with out_pl: display(img.to_thumb(128,128)) pred,pred_idx,probs = learn_inf.predict(img) lbl_pred.value = f&#39;Prediction: {pred}; Probability: {probs[pred_idx]:.04f}&#39; btn_run.on_click(on_click_classify) . VBox([widgets.Label(&#39;Select your hotdog!&#39;), btn_upload, btn_run, out_pl, lbl_pred]) .",
            "url": "https://tobbe3108.github.io/Fast.ai.Blog/2021/02/16/Hotdog-Classifier.html",
            "relUrl": "/2021/02/16/Hotdog-Classifier.html",
            "date": " • Feb 16, 2021"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://tobbe3108.github.io/Fast.ai.Blog/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://tobbe3108.github.io/Fast.ai.Blog/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}