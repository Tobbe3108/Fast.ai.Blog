{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "jupytext": {
      "split_at_heading": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "colab": {
      "name": "2021-03-02-Under-the-Hood.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "orcRQFSdBoTs"
      },
      "source": [
        "#hide\n",
        "!pip install -Uqq fastbook\n",
        "import fastbook\n",
        "fastbook.setup_book()"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0NOPE20tBoTu"
      },
      "source": [
        "#hide\n",
        "from fastai.vision.all import *\n",
        "from fastbook import *\n",
        "\n",
        "matplotlib.rc('image', cmap='Greys')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SXV1j92qBoUB"
      },
      "source": [
        "## Putting It All Together"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W6Y_XpmcCEg6"
      },
      "source": [
        "def init_params(size, std=1.0): return (torch.randn(size)*std).requires_grad_()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AvOE0tl6BoUB"
      },
      "source": [
        "weights = init_params((28*28,1))\n",
        "bias = init_params(1)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UOinbqAwwiQo"
      },
      "source": [
        "path = untar_data(URLs.MNIST)\r\n",
        "Path.BASE_PATH = path\r\n",
        "path.ls()\r\n",
        "(path/'training').ls()\r\n",
        "\r\n",
        "zeroes = (path/'training'/'0').ls().sorted()\r\n",
        "ones = (path/'training'/'1').ls().sorted()\r\n",
        "twos = (path/'training'/'2').ls().sorted()\r\n",
        "threes = (path/'training'/'3').ls().sorted()\r\n",
        "fours = (path/'training'/'4').ls().sorted()\r\n",
        "fives = (path/'training'/'5').ls().sorted()\r\n",
        "sixes = (path/'training'/'6').ls().sorted()\r\n",
        "sevens = (path/'training'/'7').ls().sorted()\r\n",
        "eights = (path/'training'/'8').ls().sorted()\r\n",
        "nines = (path/'training'/'9').ls().sorted()\r\n",
        "\r\n",
        "zeroes_tensors = [tensor(Image.open(o)) for o in zeroes]\r\n",
        "ones_tensors = [tensor(Image.open(o)) for o in ones]\r\n",
        "twoes_tensors = [tensor(Image.open(o)) for o in twos]\r\n",
        "threes_tensors = [tensor(Image.open(o)) for o in threes]\r\n",
        "fours_tensors = [tensor(Image.open(o)) for o in fours]\r\n",
        "fives_tensors = [tensor(Image.open(o)) for o in fives]\r\n",
        "sixes_tensors = [tensor(Image.open(o)) for o in sixes]\r\n",
        "seven_tensors = [tensor(Image.open(o)) for o in sevens]\r\n",
        "eights_tensors = [tensor(Image.open(o)) for o in eights]\r\n",
        "nines_tensors = [tensor(Image.open(o)) for o in nines]\r\n",
        "\r\n",
        "stacked_zeroes = torch.stack(zeroes_tensors).float()/255\r\n",
        "stacked_ones = torch.stack(ones_tensors).float()/255\r\n",
        "stacked_twos = torch.stack(twoes_tensors).float()/255\r\n",
        "stacked_threes = torch.stack(threes_tensors).float()/255\r\n",
        "stacked_fours = torch.stack(fours_tensors).float()/255\r\n",
        "stacked_fives = torch.stack(fives_tensors).float()/255\r\n",
        "stacked_sixes = torch.stack(sixes_tensors).float()/255\r\n",
        "stacked_sevens = torch.stack(seven_tensors).float()/255\r\n",
        "stacked_eights = torch.stack(eights_tensors).float()/255\r\n",
        "stacked_nines = torch.stack(nines_tensors).float()/255\r\n",
        "\r\n",
        "train_x = torch.cat([stacked_zeroes,stacked_ones,stacked_twos,stacked_threes,stacked_fours,stacked_fives,stacked_sixes,stacked_sevens,stacked_eights,stacked_nines]).view(-1, 28*28)\r\n",
        "train_y = tensor([0]*len(zeroes) + [1]*len(ones) + [2]*len(twos) + [3]*len(threes) + [4]*len(fours) + [5]*len(fives) + [6]*len(sixes) + [7]*len(sevens) + [8]*len(eights) + [9]*len(nines)).unsqueeze(1)\r\n",
        "\r\n",
        "dset = list(zip(train_x,train_y))\r\n",
        "\r\n",
        "dl = DataLoader(dset, batch_size=256)\r\n",
        "\r\n",
        "valid_0_tens = torch.stack([tensor(Image.open(o)) for o in (path/'testing'/'0').ls()])\r\n",
        "valid_0_tens = valid_0_tens.float()/255\r\n",
        "valid_1_tens = torch.stack([tensor(Image.open(o)) for o in (path/'testing'/'1').ls()])\r\n",
        "valid_1_tens = valid_1_tens.float()/255\r\n",
        "valid_2_tens = torch.stack([tensor(Image.open(o)) for o in (path/'testing'/'2').ls()])\r\n",
        "valid_2_tens = valid_2_tens.float()/255\r\n",
        "valid_3_tens = torch.stack([tensor(Image.open(o)) for o in (path/'testing'/'3').ls()])\r\n",
        "valid_3_tens = valid_3_tens.float()/255\r\n",
        "valid_4_tens = torch.stack([tensor(Image.open(o)) for o in (path/'testing'/'4').ls()])\r\n",
        "valid_4_tens = valid_4_tens.float()/255\r\n",
        "valid_5_tens = torch.stack([tensor(Image.open(o)) for o in (path/'testing'/'5').ls()])\r\n",
        "valid_5_tens = valid_5_tens.float()/255\r\n",
        "valid_6_tens = torch.stack([tensor(Image.open(o)) for o in (path/'testing'/'6').ls()])\r\n",
        "valid_6_tens = valid_6_tens.float()/255\r\n",
        "valid_7_tens = torch.stack([tensor(Image.open(o)) for o in (path/'testing'/'7').ls()])\r\n",
        "valid_7_tens = valid_7_tens.float()/255\r\n",
        "valid_8_tens = torch.stack([tensor(Image.open(o)) for o in (path/'testing'/'8').ls()])\r\n",
        "valid_8_tens = valid_8_tens.float()/255\r\n",
        "valid_9_tens = torch.stack([tensor(Image.open(o)) for o in (path/'testing'/'9').ls()])\r\n",
        "valid_9_tens = valid_9_tens.float()/255\r\n",
        "\r\n",
        "valid_x = torch.cat([valid_0_tens, valid_1_tens, valid_2_tens, valid_3_tens, valid_4_tens, valid_5_tens, valid_6_tens, valid_7_tens, valid_8_tens, valid_9_tens]).view(-1, 28*28)\r\n",
        "valid_y = tensor([0]*len(valid_0_tens) + [1]*len(valid_1_tens) + [2]*len(valid_2_tens) + [3]*len(valid_3_tens) + [4]*len(valid_4_tens) + [5]*len(valid_5_tens) + [6]*len(valid_6_tens) + [7]*len(valid_7_tens) + [8]*len(valid_8_tens) + [9]*len(valid_9_tens)).unsqueeze(1)\r\n",
        "valid_dset = list(zip(valid_x,valid_y))\r\n",
        "\r\n",
        "valid_dl = DataLoader(valid_dset, batch_size=256)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKmADfVAvjwF"
      },
      "source": [
        "path = untar_data(URLs.MNIST_SAMPLE)\r\n",
        "Path.BASE_PATH = path\r\n",
        "path.ls()\r\n",
        "(path/'train').ls()\r\n",
        "\r\n",
        "threes = (path/'train'/'3').ls().sorted()\r\n",
        "sevens = (path/'train'/'7').ls().sorted()\r\n",
        "\r\n",
        "seven_tensors = [tensor(Image.open(o)) for o in sevens]\r\n",
        "three_tensors = [tensor(Image.open(o)) for o in threes]\r\n",
        "\r\n",
        "stacked_sevens = torch.stack(seven_tensors).float()/255\r\n",
        "stacked_threes = torch.stack(three_tensors).float()/255\r\n",
        "\r\n",
        "train_x = torch.cat([stacked_threes, stacked_sevens]).view(-1, 28*28)\r\n",
        "train_y = tensor([1]*len(threes) + [0]*len(sevens)).unsqueeze(1)\r\n",
        "\r\n",
        "dset = list(zip(train_x,train_y))\r\n",
        "\r\n",
        "dl = DataLoader(dset, batch_size=256)\r\n",
        "\r\n",
        "valid_3_tens = torch.stack([tensor(Image.open(o)) \r\n",
        "                            for o in (path/'valid'/'3').ls()])\r\n",
        "valid_3_tens = valid_3_tens.float()/255\r\n",
        "valid_7_tens = torch.stack([tensor(Image.open(o)) \r\n",
        "                            for o in (path/'valid'/'7').ls()])\r\n",
        "valid_7_tens = valid_7_tens.float()/255\r\n",
        "valid_3_tens.shape,valid_7_tens.shape\r\n",
        "\r\n",
        "valid_x = torch.cat([valid_3_tens, valid_7_tens]).view(-1, 28*28)\r\n",
        "valid_y = tensor([1]*len(valid_3_tens) + [0]*len(valid_7_tens)).unsqueeze(1)\r\n",
        "valid_dset = list(zip(valid_x,valid_y))\r\n",
        "\r\n",
        "valid_dl = DataLoader(valid_dset, batch_size=256)"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4UsTo2vMBoUC"
      },
      "source": [
        "batch = train_x[:4]"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PFlz4xGaFp4p"
      },
      "source": [
        "def linear1(xb): return xb@weights + bias"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mK2Bm4ghBoUC"
      },
      "source": [
        "preds = linear1(batch)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ybxxi3jkGtAv"
      },
      "source": [
        "def sigmoid(x): return 1/(1+torch.exp(-x))"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nLbDh_haGtqF"
      },
      "source": [
        "def mnist_loss(predictions, targets):\r\n",
        "    predictions = predictions.sigmoid()\r\n",
        "    return torch.where(targets==1, 1-predictions, predictions).mean()"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NoRUZGOyBoUC"
      },
      "source": [
        "loss = mnist_loss(preds, train_y[:4])"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FfiSsA2QBoUC",
        "outputId": "b11ceeec-4104-43d0-d19f-7a4378199726"
      },
      "source": [
        "loss.backward()\n",
        "weights.grad.shape,weights.grad.mean(),bias.grad"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([784, 1]), tensor(4.4802e-05), tensor([0.0003]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qwwtL5adBoUC"
      },
      "source": [
        "def calc_grad(xb, yb, model):\n",
        "    preds = model(xb)\n",
        "    loss = mnist_loss(preds, yb)\n",
        "    loss.backward()"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ILEfwioDBoUC",
        "outputId": "c1f15ab0-0493-48cb-9ebf-83e48dbed7a9"
      },
      "source": [
        "calc_grad(batch, train_y[:4], linear1)\n",
        "weights.grad.mean(),bias.grad"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(8.9603e-05), tensor([0.0005]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fu5iJTkVBoUC",
        "outputId": "e88dab2e-4494-4280-e1a2-56cc5f90da05"
      },
      "source": [
        "calc_grad(batch, train_y[:4], linear1)\n",
        "weights.grad.mean(),bias.grad"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.0001), tensor([0.0008]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wNSDGRu3BoUC"
      },
      "source": [
        "weights.grad.zero_()\n",
        "bias.grad.zero_();"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "It9uc-ItBoUD"
      },
      "source": [
        "def train_epoch(model, lr, params):\n",
        "    for xb,yb in dl:\n",
        "        calc_grad(xb, yb, model)\n",
        "        for p in params:\n",
        "            p.data -= p.grad*lr\n",
        "            p.grad.zero_()"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "utNeSvUQBoUD",
        "outputId": "0435fb74-70e4-429b-d417-c22c33cd0a2e"
      },
      "source": [
        "(preds>0.0).float() == train_y[:4]"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[True],\n",
              "        [True],\n",
              "        [True],\n",
              "        [True]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LB5S8qREBoUD"
      },
      "source": [
        "def batch_accuracy(xb, yb):\n",
        "    preds = xb.sigmoid()\n",
        "    correct = (preds>0.5) == yb\n",
        "    return correct.float().mean()"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xF2Fk-znBoUD",
        "outputId": "26f79704-d6a3-465d-b8ed-c5b1e1f89c35"
      },
      "source": [
        "batch_accuracy(linear1(batch), train_y[:4])"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1.)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WmGvqVUzBoUD"
      },
      "source": [
        "def validate_epoch(model):\n",
        "    accs = [batch_accuracy(model(xb), yb) for xb,yb in valid_dl]\n",
        "    return round(torch.stack(accs).mean().item(), 4)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E0CGpa80BoUD",
        "outputId": "8112af4f-33fe-400a-f631-d152e5d60f42"
      },
      "source": [
        "validate_epoch(linear1)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0942"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6GDqzYE0BoUD",
        "outputId": "7248cadc-7d9b-4abe-e37c-713ea1e71b15"
      },
      "source": [
        "lr = 1.\n",
        "params = weights,bias\n",
        "train_epoch(linear1, lr, params)\n",
        "validate_epoch(linear1)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.098"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q-3bqqb4BoUD",
        "outputId": "fba66d49-2857-48ea-8e1a-814bb6a7c00e"
      },
      "source": [
        "for i in range(20):\n",
        "    train_epoch(linear1, lr, params)\n",
        "    print(validate_epoch(linear1), end=' ')"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.098 0.098 0.0991 0.1001 0.102 0.1033 0.1048 0.1057 0.1066 0.1074 0.1086 0.1095 0.1099 0.1106 0.1119 0.1124 0.1133 0.1134 0.114 0.1147 "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MYduBjJv59V_"
      },
      "source": [
        "dls = DataLoaders(dl, valid_dl)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RUOi6X2ZBoUE"
      },
      "source": [
        "### Creating an Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nMNJ0jlwBoUE"
      },
      "source": [
        "linear_model = nn.Linear(28*28,1)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jI0M-4zlBoUE"
      },
      "source": [
        "w,b = linear_model.parameters()"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7nc0-s5aBoUE"
      },
      "source": [
        "class BasicOptim:\n",
        "    def __init__(self,params,lr): self.params,self.lr = list(params),lr\n",
        "\n",
        "    def step(self, *args, **kwargs):\n",
        "        for p in self.params: p.data -= p.grad.data * self.lr\n",
        "\n",
        "    def zero_grad(self, *args, **kwargs):\n",
        "        for p in self.params: p.grad = None"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mbRuNxqMBoUE"
      },
      "source": [
        "opt = BasicOptim(linear_model.parameters(), lr)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KyWU8PP-BoUE"
      },
      "source": [
        "def train_epoch(model):\n",
        "    for xb,yb in dl:\n",
        "        calc_grad(xb, yb, model)\n",
        "        opt.step()\n",
        "        opt.zero_grad()"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TQ-sJeRuBoUE",
        "outputId": "b81e2851-b8b3-45f3-ce3f-fb48f97a431f"
      },
      "source": [
        "validate_epoch(linear_model)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0769"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mmsEmUWxBoUE"
      },
      "source": [
        "def train_model(model, epochs):\n",
        "    for i in range(epochs):\n",
        "        train_epoch(model)\n",
        "        print(validate_epoch(model), end=' ')"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jebuf9LKBoUF",
        "outputId": "ea6ccd89-2340-420f-8721-39d890a511ca"
      },
      "source": [
        "train_model(linear_model, 20)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.098 0.098 0.098 0.098 0.0982 0.0984 0.0988 0.0998 0.1006 0.1021 0.1038 0.1052 0.1063 0.1067 0.107 0.1072 0.1082 0.1088 0.1089 0.1087 "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ClGl4CPuBoUF",
        "outputId": "9c49e5c3-4ad2-4609-a4fe-491ef38463bc"
      },
      "source": [
        "linear_model = nn.Linear(28*28,1)\n",
        "opt = SGD(linear_model.parameters(), lr)\n",
        "train_model(linear_model, 20)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.098 0.098 0.098 0.098 0.0982 0.0984 0.0987 0.0994 0.0998 0.101 0.1025 0.1041 0.1056 0.1063 0.1064 0.1066 0.1075 0.108 0.1079 0.1085 "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dNlR7L5vqLSv"
      },
      "source": [
        "learn = Learner(dls, nn.Linear(28*28,1), opt_func=SGD,\r\n",
        "loss_func=mnist_loss, metrics=batch_accuracy)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wzxToiwlqNl3",
        "outputId": "f7bd47f8-2da7-4d97-e860-e2140cc4862e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 601
        }
      },
      "source": [
        "learn.fit(10, lr=lr)"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='7' class='' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      70.00% [7/10 00:12<00:05]\n",
              "    </div>\n",
              "    \n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>batch_accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.000645</td>\n",
              "      <td>0.104988</td>\n",
              "      <td>0.104700</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.000482</td>\n",
              "      <td>0.086720</td>\n",
              "      <td>0.124500</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.000608</td>\n",
              "      <td>0.078033</td>\n",
              "      <td>0.133400</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.000694</td>\n",
              "      <td>0.074158</td>\n",
              "      <td>0.136800</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.000642</td>\n",
              "      <td>0.073499</td>\n",
              "      <td>0.138000</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.000617</td>\n",
              "      <td>0.051463</td>\n",
              "      <td>0.160400</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.000546</td>\n",
              "      <td>0.070548</td>\n",
              "      <td>0.141000</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>\n",
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='71' class='' max='235' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      30.21% [71/235 00:00<00:01 0.0107]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-74-1743e6f42408>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/fastai/learner.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, n_epoch, lr, wd, cbs, reset_opt)\u001b[0m\n\u001b[1;32m    209\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_hypers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn_epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_with_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_fit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fit'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCancelFitException\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_end_cleanup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_end_cleanup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/fastai/learner.py\u001b[0m in \u001b[0;36m_with_events\u001b[0;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_with_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnoop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'before_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m  \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'after_cancel_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'after_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m  \u001b[0mfinal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/fastai/learner.py\u001b[0m in \u001b[0;36m_do_fit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_with_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'epoch'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCancelEpochException\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcbs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset_opt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/fastai/learner.py\u001b[0m in \u001b[0;36m_with_events\u001b[0;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_with_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnoop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'before_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m  \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'after_cancel_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'after_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m  \u001b[0mfinal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/fastai/learner.py\u001b[0m in \u001b[0;36m_do_epoch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_do_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_epoch_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_epoch_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/fastai/learner.py\u001b[0m in \u001b[0;36m_do_epoch_train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_do_epoch_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_with_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_batches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCancelTrainException\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_do_epoch_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mds_idx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/fastai/learner.py\u001b[0m in \u001b[0;36m_with_events\u001b[0;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_with_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnoop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'before_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m  \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'after_cancel_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'after_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m  \u001b[0mfinal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/fastai/learner.py\u001b[0m in \u001b[0;36mall_batches\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mall_batches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_do_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/fastai/learner.py\u001b[0m in \u001b[0;36mone_batch\u001b[0;34m(self, i, b)\u001b[0m\n\u001b[1;32m    182\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_with_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_one_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'batch'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCancelBatchException\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_do_epoch_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/fastai/learner.py\u001b[0m in \u001b[0;36m_with_events\u001b[0;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_with_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnoop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'before_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m  \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'after_cancel_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'after_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m  \u001b[0mfinal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/fastai/learner.py\u001b[0m in \u001b[0;36m_do_one_batch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_do_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'after_pred'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1688\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1689\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1690\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1691\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1692\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_YQvoWvqBoUG"
      },
      "source": [
        "## Adding a Nonlinearity"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SmAnh0trOV8g",
        "outputId": "cbf87db0-183a-474f-8bae-7c06d42e4fd6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "features = 90\r\n",
        "nrOfLayers = 0\r\n",
        "\r\n",
        "layers = []\r\n",
        "layers.append(nn.Linear(28*28,features))\r\n",
        "\r\n",
        "for i in range(nrOfLayers):\r\n",
        "  layers.append(nn.ReLU())\r\n",
        "  layers.append(nn.Linear(features,features))\r\n",
        "\r\n",
        "layers.append(nn.ReLU())\r\n",
        "layers.append(nn.Linear(features,1))\r\n",
        "\r\n",
        "print('Nr of layers', len(layers)) \r\n",
        "layers"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Nr of layers 3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Linear(in_features=784, out_features=90, bias=True),\n",
              " ReLU(),\n",
              " Linear(in_features=90, out_features=1, bias=True)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cn6o0aMtBoUG"
      },
      "source": [
        "simple_net = nn.Sequential(*layers)"
      ],
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ib_BVvp1BoUG"
      },
      "source": [
        "learn = Learner(dls, simple_net, opt_func=SGD,\n",
        "                loss_func=mnist_loss, metrics=batch_accuracy)"
      ],
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "xK1Lqc9YBoUG",
        "outputId": "6e36a6c6-e30a-4b26-d940-acd9fe7b1ae4"
      },
      "source": [
        "learn.fit(50, 1.0)"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>batch_accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.002604</td>\n",
              "      <td>0.111212</td>\n",
              "      <td>0.098000</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.001329</td>\n",
              "      <td>0.097870</td>\n",
              "      <td>0.107700</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.000930</td>\n",
              "      <td>0.092041</td>\n",
              "      <td>0.117100</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.000873</td>\n",
              "      <td>0.087795</td>\n",
              "      <td>0.121700</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.000879</td>\n",
              "      <td>0.083624</td>\n",
              "      <td>0.127600</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.000905</td>\n",
              "      <td>0.079636</td>\n",
              "      <td>0.132200</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.000929</td>\n",
              "      <td>0.076391</td>\n",
              "      <td>0.135000</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.000950</td>\n",
              "      <td>0.073506</td>\n",
              "      <td>0.138300</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.000969</td>\n",
              "      <td>0.070597</td>\n",
              "      <td>0.142000</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.000986</td>\n",
              "      <td>0.068260</td>\n",
              "      <td>0.143900</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.000994</td>\n",
              "      <td>0.065818</td>\n",
              "      <td>0.146200</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.001001</td>\n",
              "      <td>0.063694</td>\n",
              "      <td>0.148500</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.001001</td>\n",
              "      <td>0.061537</td>\n",
              "      <td>0.151300</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.001010</td>\n",
              "      <td>0.060394</td>\n",
              "      <td>0.152500</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.001007</td>\n",
              "      <td>0.057467</td>\n",
              "      <td>0.156200</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>0.001005</td>\n",
              "      <td>0.056069</td>\n",
              "      <td>0.156900</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>0.000996</td>\n",
              "      <td>0.053122</td>\n",
              "      <td>0.159900</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>0.000986</td>\n",
              "      <td>0.051553</td>\n",
              "      <td>0.161300</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>0.000975</td>\n",
              "      <td>0.048800</td>\n",
              "      <td>0.164000</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>0.000966</td>\n",
              "      <td>0.047040</td>\n",
              "      <td>0.165600</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.000969</td>\n",
              "      <td>0.043970</td>\n",
              "      <td>0.168400</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21</td>\n",
              "      <td>0.000975</td>\n",
              "      <td>0.042065</td>\n",
              "      <td>0.170500</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22</td>\n",
              "      <td>0.000990</td>\n",
              "      <td>0.039492</td>\n",
              "      <td>0.173400</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23</td>\n",
              "      <td>0.001000</td>\n",
              "      <td>0.037980</td>\n",
              "      <td>0.174700</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>0.001019</td>\n",
              "      <td>0.035686</td>\n",
              "      <td>0.177400</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>0.001035</td>\n",
              "      <td>0.034079</td>\n",
              "      <td>0.179400</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26</td>\n",
              "      <td>0.001046</td>\n",
              "      <td>0.032285</td>\n",
              "      <td>0.180800</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27</td>\n",
              "      <td>0.001055</td>\n",
              "      <td>0.031533</td>\n",
              "      <td>0.181700</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28</td>\n",
              "      <td>0.001062</td>\n",
              "      <td>0.029820</td>\n",
              "      <td>0.183700</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29</td>\n",
              "      <td>0.001072</td>\n",
              "      <td>0.028288</td>\n",
              "      <td>0.185300</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>0.001073</td>\n",
              "      <td>0.027617</td>\n",
              "      <td>0.185900</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>31</td>\n",
              "      <td>0.001085</td>\n",
              "      <td>0.026700</td>\n",
              "      <td>0.186500</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32</td>\n",
              "      <td>0.001088</td>\n",
              "      <td>0.025756</td>\n",
              "      <td>0.187500</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>33</td>\n",
              "      <td>0.001095</td>\n",
              "      <td>0.025093</td>\n",
              "      <td>0.188400</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>34</td>\n",
              "      <td>0.001098</td>\n",
              "      <td>0.024270</td>\n",
              "      <td>0.189000</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35</td>\n",
              "      <td>0.001102</td>\n",
              "      <td>0.023724</td>\n",
              "      <td>0.189600</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>36</td>\n",
              "      <td>0.001105</td>\n",
              "      <td>0.023301</td>\n",
              "      <td>0.189800</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>37</td>\n",
              "      <td>0.001107</td>\n",
              "      <td>0.022698</td>\n",
              "      <td>0.190600</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>38</td>\n",
              "      <td>0.001108</td>\n",
              "      <td>0.022417</td>\n",
              "      <td>0.190800</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>39</td>\n",
              "      <td>0.001104</td>\n",
              "      <td>0.021719</td>\n",
              "      <td>0.191500</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>0.001099</td>\n",
              "      <td>0.021492</td>\n",
              "      <td>0.191900</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>41</td>\n",
              "      <td>0.001093</td>\n",
              "      <td>0.020864</td>\n",
              "      <td>0.192200</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>42</td>\n",
              "      <td>0.001094</td>\n",
              "      <td>0.020424</td>\n",
              "      <td>0.192400</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>43</td>\n",
              "      <td>0.001087</td>\n",
              "      <td>0.019747</td>\n",
              "      <td>0.192900</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>44</td>\n",
              "      <td>0.001084</td>\n",
              "      <td>0.019268</td>\n",
              "      <td>0.193500</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>45</td>\n",
              "      <td>0.001072</td>\n",
              "      <td>0.018620</td>\n",
              "      <td>0.194400</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>46</td>\n",
              "      <td>0.001062</td>\n",
              "      <td>0.018115</td>\n",
              "      <td>0.194900</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>47</td>\n",
              "      <td>0.001046</td>\n",
              "      <td>0.017500</td>\n",
              "      <td>0.195700</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>48</td>\n",
              "      <td>0.001021</td>\n",
              "      <td>0.016856</td>\n",
              "      <td>0.196400</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>49</td>\n",
              "      <td>0.000998</td>\n",
              "      <td>0.016313</td>\n",
              "      <td>0.196700</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "id": "NhK1L7ReBoUG",
        "outputId": "f61ba749-f8e4-47c2-9def-060972d3ef93"
      },
      "source": [
        "plt.plot(L(learn.recorder.values).itemgot(2));"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v9liv-BoBoUH",
        "outputId": "e31407d0-a5bd-4b97-c844-329dc0921302"
      },
      "source": [
        "learn.recorder.values[-1][2]"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.19670000672340393"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 100
        }
      ]
    }
  ]
}